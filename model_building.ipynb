{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bp/y9d0ptkd29x0bjnqq6w8mq980000gn/T/ipykernel_33881/704855704.py:9: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('merged_data.csv')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('merged_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string representation of list to actual list for Genres column\n",
    "df['Genres'] = df['Genres'].apply(literal_eval)\n",
    "\n",
    "# Step 1: Zero-Index all categorical features\n",
    "df[\"UserID\"] = df[\"UserID\"] - 1  # Zero-index UserID\n",
    "df[\"MovieID\"] = df[\"MovieID\"] - 1  # Zero-index MovieID\n",
    "df[\"Gender\"] = df[\"Gender\"].astype('category').cat.codes  # Zero-index Gender\n",
    "df[\"Occupation\"] = df[\"Occupation\"].astype('category').cat.codes  # Zero-index Occupation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Split data by user age group or any criteria you want to simulate clients\n",
    "age_groups = df['Age'].unique()\n",
    "client_datasets = {}\n",
    "\n",
    "# Create simulated client datasets based on age groups\n",
    "for age in age_groups:\n",
    "    client_data = df[df['Age'] == age]\n",
    "    client_datasets[f\"client_{age}\"] = client_data\n",
    "\n",
    "# Get all unique genres from the dataset\n",
    "all_genres = set()\n",
    "for genres in df['Genres']:\n",
    "    all_genres.update(genres)\n",
    "all_genres = sorted(all_genres)\n",
    "num_genres = len(all_genres)\n",
    "\n",
    "# Create genre mapping\n",
    "genre_to_idx = {genre: i for i, genre in enumerate(all_genres)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Federated Recommender Model using PyTorch\n",
    "class FederatedRecommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, num_genders, num_occupations, num_genres, embedding_dim=10):\n",
    "        super(FederatedRecommender, self).__init__()\n",
    "        \n",
    "        # Embeddings for each feature\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_embedding = nn.Embedding(num_movies, embedding_dim)\n",
    "        self.gender_embedding = nn.Embedding(num_genders, embedding_dim)\n",
    "        self.occupation_embedding = nn.Embedding(num_occupations, embedding_dim)\n",
    "        \n",
    "        # Genre embeddings - we'll use a linear layer\n",
    "        self.genre_projection = nn.Linear(num_genres, embedding_dim)\n",
    "        \n",
    "        # Fully connected layers for rating prediction\n",
    "        self.fc1 = nn.Linear(embedding_dim * 5, 128)  # 5 features: user, movie, gender, occupation, genres\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, user, movie, gender, occupation, genres):\n",
    "        # Embedding lookup\n",
    "        user_embedded = self.user_embedding(user)\n",
    "        movie_embedded = self.movie_embedding(movie)\n",
    "        gender_embedded = self.gender_embedding(gender)\n",
    "        occupation_embedded = self.occupation_embedding(occupation)\n",
    "        \n",
    "        # Process genres - project binary flags to embedding space\n",
    "        genre_embedded = self.genre_projection(genres.float())\n",
    "        \n",
    "        # Concatenate all embeddings\n",
    "        all_embeddings = torch.cat([\n",
    "            user_embedded, \n",
    "            movie_embedded, \n",
    "            gender_embedded, \n",
    "            occupation_embedded,\n",
    "            genre_embedded\n",
    "        ], dim=-1)\n",
    "        \n",
    "        # Pass through fully connected layers\n",
    "        x = torch.relu(self.fc1(all_embeddings))\n",
    "        rating = self.fc2(x)\n",
    "        return rating.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Federated learning training function for each client\n",
    "def train_local_model(client_data, model, epochs=75, batch_size=64, lr=0.001, weight_decay=0.01):\n",
    "    \"\"\"\n",
    "    Train the local model using the client's data.\n",
    "\n",
    "    Args:\n",
    "    - client_data: The dataset for the current client (a DataFrame).\n",
    "    - model: The FederatedRecommender model to train.\n",
    "    - epochs: The number of epochs to train for.\n",
    "    - batch_size: The batch size for training.\n",
    "    - lr: The learning rate.\n",
    "    - weight_decay: The weight decay (L2 regularization).\n",
    "\n",
    "    Returns:\n",
    "    - trained_model: The trained model.\n",
    "    - final_loss: The final loss after training.\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare the data\n",
    "    user = torch.tensor(client_data['UserID'].values, dtype=torch.long)\n",
    "    movie = torch.tensor(client_data['MovieID'].values, dtype=torch.long)\n",
    "    gender = torch.tensor(client_data['Gender'].values, dtype=torch.long)\n",
    "    occupation = torch.tensor(client_data['Occupation'].values, dtype=torch.long)\n",
    "    \n",
    "    # Create genre vectors\n",
    "    genre_vectors = []\n",
    "    for genres in client_data['Genres']:\n",
    "        vec = torch.zeros(num_genres)\n",
    "        for genre in genres:\n",
    "            if genre in genre_to_idx:  # Check if genre is in the index map\n",
    "                vec[genre_to_idx[genre]] = 1\n",
    "        genre_vectors.append(vec)\n",
    "    genres = torch.stack(genre_vectors)\n",
    "    \n",
    "    ratings = torch.tensor(client_data['Rating'].values, dtype=torch.float32)\n",
    "\n",
    "    # Create a DataLoader to batch the data\n",
    "    dataset = TensorDataset(user, movie, gender, occupation, genres, ratings)\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize the optimizer, loss function, and learning rate scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)  # Using AdamW optimizer with weight decay\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)  # Learning rate scheduler to decay after 10 epochs\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Loop through mini-batches\n",
    "        for batch in data_loader:\n",
    "            user_batch, movie_batch, gender_batch, occupation_batch, genres_batch, ratings_batch = batch\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            predictions = model(user_batch, movie_batch, gender_batch, occupation_batch, genres_batch)\n",
    "            \n",
    "            # Compute the loss\n",
    "            loss = criterion(predictions.squeeze(), ratings_batch)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update running loss for the current epoch\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        avg_loss = running_loss / len(data_loader)\n",
    "        print(f\"Client Training Epoch {epoch+1}/{epochs} - Avg Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "    return model, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client Training Epoch 1/75 - Avg Loss: 1.9037\n",
      "Client Training Epoch 2/75 - Avg Loss: 1.3371\n",
      "Client Training Epoch 3/75 - Avg Loss: 1.2720\n",
      "Client Training Epoch 4/75 - Avg Loss: 1.2141\n",
      "Client Training Epoch 5/75 - Avg Loss: 1.1651\n",
      "Client Training Epoch 6/75 - Avg Loss: 1.1165\n",
      "Client Training Epoch 7/75 - Avg Loss: 1.0727\n",
      "Client Training Epoch 8/75 - Avg Loss: 1.0371\n",
      "Client Training Epoch 9/75 - Avg Loss: 1.0041\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.9709\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.9323\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.9168\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.9001\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.8910\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.8801\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.8677\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.8562\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.8471\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.8364\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.8264\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.8070\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.8011\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.7973\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.7916\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.7874\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.7842\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.7798\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.7760\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.7712\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.7664\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.7577\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.7544\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.7521\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.7503\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.7486\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.7475\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.7435\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.7428\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.7406\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.7383\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.7361\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.7336\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.7321\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.7314\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.7300\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.7280\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.7281\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.7261\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.7265\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.7248\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.7217\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.7209\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.7206\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.7209\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.7211\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.7195\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.7190\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.7180\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.7181\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.7176\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.7157\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.7161\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.7147\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.7157\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.7152\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.7149\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.7154\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.7157\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.7145\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.7143\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.7128\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.7128\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.7139\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.7130\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.7125\n",
      "💾 Saved model for client_1 to client_models/client_model_1.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.5739\n",
      "Client Training Epoch 2/75 - Avg Loss: 0.9640\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.9151\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.8745\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.8383\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.8069\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.7823\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.7577\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.7365\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.7187\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.6889\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.6791\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.6714\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.6640\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.6578\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.6502\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.6442\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.6375\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.6305\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.6241\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.6104\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.6067\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.6041\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.6005\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.5981\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.5955\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.5924\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.5898\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.5874\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.5838\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.5768\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.5748\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.5734\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.5723\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.5711\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.5695\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.5682\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.5671\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.5657\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.5643\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.5605\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.5595\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.5589\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.5582\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.5575\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.5569\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.5562\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.5556\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.5551\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.5545\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.5523\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.5518\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.5516\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.5512\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.5509\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.5506\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.5503\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.5500\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.5496\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.5493\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.5483\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.5481\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.5479\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.5478\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.5476\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.5475\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.5473\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.5471\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.5470\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.5468\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.5462\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.5461\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.5461\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.5460\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.5459\n",
      "💾 Saved model for client_56 to client_models/client_model_56.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.0974\n",
      "Client Training Epoch 2/75 - Avg Loss: 0.8631\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.8250\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.8116\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.8033\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.7962\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.7891\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.7825\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.7755\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.7688\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.7488\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.7432\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.7389\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.7348\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.7307\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.7266\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.7223\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.7188\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.7145\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.7108\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.6974\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.6943\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.6918\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.6897\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.6878\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.6858\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.6840\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.6819\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.6804\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.6786\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.6707\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.6693\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.6682\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.6673\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.6663\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.6654\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.6646\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.6636\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.6628\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.6619\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.6574\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.6568\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.6563\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.6559\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.6554\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.6550\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.6546\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.6541\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.6537\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.6532\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.6508\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.6505\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.6503\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.6501\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.6499\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.6496\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.6494\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.6492\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.6490\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.6489\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.6476\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.6474\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.6473\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.6472\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.6471\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.6470\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.6469\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.6469\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.6468\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.6467\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.6460\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.6459\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.6459\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.6458\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.6458\n",
      "💾 Saved model for client_25 to client_models/client_model_25.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.2624\n",
      "Client Training Epoch 2/75 - Avg Loss: 0.9522\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.8844\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.8325\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.7967\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.7709\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.7501\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.7344\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.7218\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.7115\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.6882\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.6823\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.6769\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.6725\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.6679\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.6636\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.6603\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.6564\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.6527\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.6486\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.6363\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.6339\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.6319\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.6296\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.6277\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.6256\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.6243\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.6219\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.6208\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.6188\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.6120\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.6105\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.6095\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.6084\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.6077\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.6065\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.6059\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.6049\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.6040\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.6033\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.5994\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.5989\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.5984\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.5977\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.5973\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.5970\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.5966\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.5962\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.5955\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.5950\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.5933\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.5929\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.5927\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.5925\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.5923\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.5921\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.5918\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.5916\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.5913\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.5912\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.5901\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.5900\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.5899\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.5897\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.5897\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.5896\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.5895\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.5894\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.5893\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.5893\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.5886\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.5885\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.5885\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.5884\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.5884\n",
      "💾 Saved model for client_45 to client_models/client_model_45.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.2688\n",
      "Client Training Epoch 2/75 - Avg Loss: 0.9480\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.8898\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.8403\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.8031\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.7720\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.7486\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.7311\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.7140\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.7029\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.6777\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.6713\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.6662\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.6606\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.6563\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.6517\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.6466\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.6424\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.6380\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.6339\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.6213\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.6179\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.6163\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.6140\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.6114\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.6095\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.6080\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.6056\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.6038\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.6018\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.5945\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.5932\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.5922\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.5912\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.5900\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.5892\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.5881\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.5874\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.5863\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.5853\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.5817\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.5809\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.5804\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.5799\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.5794\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.5789\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.5783\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.5779\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.5775\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.5769\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.5750\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.5746\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.5744\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.5740\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.5738\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.5736\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.5734\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.5732\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.5729\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.5727\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.5716\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.5716\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.5714\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.5713\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.5711\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.5710\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.5710\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.5708\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.5707\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.5706\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.5700\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.5700\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.5700\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.5698\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.5698\n",
      "💾 Saved model for client_50 to client_models/client_model_50.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.1478\n",
      "Client Training Epoch 2/75 - Avg Loss: 0.8935\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.8223\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.7897\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.7730\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.7621\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.7538\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.7454\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.7392\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.7328\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.7131\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.7084\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.7049\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.7011\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.6977\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.6941\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.6906\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.6873\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.6840\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.6809\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.6683\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.6660\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.6640\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.6621\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.6601\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.6584\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.6569\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.6552\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.6531\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.6518\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.6445\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.6436\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.6425\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.6414\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.6407\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.6397\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.6388\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.6382\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.6372\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.6364\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.6324\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.6318\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.6314\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.6310\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.6305\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.6300\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.6296\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.6292\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.6287\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.6283\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.6262\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.6260\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.6258\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.6256\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.6253\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.6251\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.6249\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.6246\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.6245\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.6242\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.6232\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.6231\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.6229\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.6228\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.6227\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.6226\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.6225\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.6224\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.6223\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.6222\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.6216\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.6216\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.6215\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.6214\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.6215\n",
      "💾 Saved model for client_35 to client_models/client_model_35.pth\n",
      "Client Training Epoch 1/75 - Avg Loss: 1.2886\n",
      "Client Training Epoch 2/75 - Avg Loss: 1.0056\n",
      "Client Training Epoch 3/75 - Avg Loss: 0.9240\n",
      "Client Training Epoch 4/75 - Avg Loss: 0.8886\n",
      "Client Training Epoch 5/75 - Avg Loss: 0.8683\n",
      "Client Training Epoch 6/75 - Avg Loss: 0.8547\n",
      "Client Training Epoch 7/75 - Avg Loss: 0.8447\n",
      "Client Training Epoch 8/75 - Avg Loss: 0.8369\n",
      "Client Training Epoch 9/75 - Avg Loss: 0.8293\n",
      "Client Training Epoch 10/75 - Avg Loss: 0.8221\n",
      "Client Training Epoch 11/75 - Avg Loss: 0.8015\n",
      "Client Training Epoch 12/75 - Avg Loss: 0.7959\n",
      "Client Training Epoch 13/75 - Avg Loss: 0.7921\n",
      "Client Training Epoch 14/75 - Avg Loss: 0.7881\n",
      "Client Training Epoch 15/75 - Avg Loss: 0.7843\n",
      "Client Training Epoch 16/75 - Avg Loss: 0.7808\n",
      "Client Training Epoch 17/75 - Avg Loss: 0.7770\n",
      "Client Training Epoch 18/75 - Avg Loss: 0.7730\n",
      "Client Training Epoch 19/75 - Avg Loss: 0.7697\n",
      "Client Training Epoch 20/75 - Avg Loss: 0.7664\n",
      "Client Training Epoch 21/75 - Avg Loss: 0.7528\n",
      "Client Training Epoch 22/75 - Avg Loss: 0.7504\n",
      "Client Training Epoch 23/75 - Avg Loss: 0.7481\n",
      "Client Training Epoch 24/75 - Avg Loss: 0.7463\n",
      "Client Training Epoch 25/75 - Avg Loss: 0.7444\n",
      "Client Training Epoch 26/75 - Avg Loss: 0.7420\n",
      "Client Training Epoch 27/75 - Avg Loss: 0.7402\n",
      "Client Training Epoch 28/75 - Avg Loss: 0.7382\n",
      "Client Training Epoch 29/75 - Avg Loss: 0.7365\n",
      "Client Training Epoch 30/75 - Avg Loss: 0.7348\n",
      "Client Training Epoch 31/75 - Avg Loss: 0.7269\n",
      "Client Training Epoch 32/75 - Avg Loss: 0.7258\n",
      "Client Training Epoch 33/75 - Avg Loss: 0.7247\n",
      "Client Training Epoch 34/75 - Avg Loss: 0.7235\n",
      "Client Training Epoch 35/75 - Avg Loss: 0.7225\n",
      "Client Training Epoch 36/75 - Avg Loss: 0.7215\n",
      "Client Training Epoch 37/75 - Avg Loss: 0.7205\n",
      "Client Training Epoch 38/75 - Avg Loss: 0.7196\n",
      "Client Training Epoch 39/75 - Avg Loss: 0.7185\n",
      "Client Training Epoch 40/75 - Avg Loss: 0.7177\n",
      "Client Training Epoch 41/75 - Avg Loss: 0.7136\n",
      "Client Training Epoch 42/75 - Avg Loss: 0.7130\n",
      "Client Training Epoch 43/75 - Avg Loss: 0.7124\n",
      "Client Training Epoch 44/75 - Avg Loss: 0.7119\n",
      "Client Training Epoch 45/75 - Avg Loss: 0.7115\n",
      "Client Training Epoch 46/75 - Avg Loss: 0.7108\n",
      "Client Training Epoch 47/75 - Avg Loss: 0.7103\n",
      "Client Training Epoch 48/75 - Avg Loss: 0.7099\n",
      "Client Training Epoch 49/75 - Avg Loss: 0.7094\n",
      "Client Training Epoch 50/75 - Avg Loss: 0.7089\n",
      "Client Training Epoch 51/75 - Avg Loss: 0.7067\n",
      "Client Training Epoch 52/75 - Avg Loss: 0.7064\n",
      "Client Training Epoch 53/75 - Avg Loss: 0.7062\n",
      "Client Training Epoch 54/75 - Avg Loss: 0.7060\n",
      "Client Training Epoch 55/75 - Avg Loss: 0.7057\n",
      "Client Training Epoch 56/75 - Avg Loss: 0.7054\n",
      "Client Training Epoch 57/75 - Avg Loss: 0.7052\n",
      "Client Training Epoch 58/75 - Avg Loss: 0.7050\n",
      "Client Training Epoch 59/75 - Avg Loss: 0.7047\n",
      "Client Training Epoch 60/75 - Avg Loss: 0.7045\n",
      "Client Training Epoch 61/75 - Avg Loss: 0.7033\n",
      "Client Training Epoch 62/75 - Avg Loss: 0.7031\n",
      "Client Training Epoch 63/75 - Avg Loss: 0.7031\n",
      "Client Training Epoch 64/75 - Avg Loss: 0.7029\n",
      "Client Training Epoch 65/75 - Avg Loss: 0.7028\n",
      "Client Training Epoch 66/75 - Avg Loss: 0.7027\n",
      "Client Training Epoch 67/75 - Avg Loss: 0.7026\n",
      "Client Training Epoch 68/75 - Avg Loss: 0.7024\n",
      "Client Training Epoch 69/75 - Avg Loss: 0.7023\n",
      "Client Training Epoch 70/75 - Avg Loss: 0.7022\n",
      "Client Training Epoch 71/75 - Avg Loss: 0.7016\n",
      "Client Training Epoch 72/75 - Avg Loss: 0.7015\n",
      "Client Training Epoch 73/75 - Avg Loss: 0.7015\n",
      "Client Training Epoch 74/75 - Avg Loss: 0.7014\n",
      "Client Training Epoch 75/75 - Avg Loss: 0.7014\n",
      "💾 Saved model for client_18 to client_models/client_model_18.pth\n",
      "✅ Federated Learning Training Completed!\n",
      "📊 Validation Loss per Client: [0.7125222936902248, 0.5459206301485351, 0.6457830782732017, 0.5883505336866182, 0.569830339510464, 0.6214777208217854, 0.7013708102819477]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Federated Learning Training\n",
    "local_models = []\n",
    "validation_losses = []\n",
    "\n",
    "# Get the maximum values for each categorical feature\n",
    "num_users = df['UserID'].max() + 1\n",
    "num_movies = df['MovieID'].max() + 1\n",
    "num_genders = df['Gender'].max() + 1\n",
    "num_occupations = df['Occupation'].max() + 1\n",
    "\n",
    "for age in age_groups:\n",
    "    age_key = f\"client_{int(age)}\"\n",
    "    if age_key not in client_datasets:\n",
    "        print(f\"Skipping {age_key}, no data available.\")\n",
    "        continue\n",
    "    \n",
    "    # Initialize the model for this client\n",
    "    model = FederatedRecommender(\n",
    "        num_users=num_users, \n",
    "        num_movies=num_movies, \n",
    "        num_genders=num_genders, \n",
    "        num_occupations=num_occupations, \n",
    "        num_genres=num_genres\n",
    "    )\n",
    "    \n",
    "    # Train model locally for the current client\n",
    "    trained_model, val_loss = train_local_model(client_datasets[age_key], model)\n",
    "    # Save each trained model\n",
    "    model_save_path = f\"client_models/client_model_{int(age)}.pth\"\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    print(f\"💾 Saved model for client_{int(age)} to {model_save_path}\")\n",
    "    \n",
    "    \n",
    "    local_models.append(trained_model)\n",
    "    validation_losses.append(val_loss)\n",
    "\n",
    "# Step 5: Display training completion\n",
    "print(f\"✅ Federated Learning Training Completed!\")\n",
    "print(f\"📊 Validation Loss per Client: {validation_losses}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Federated learning model is training well on each client. The loss is steadily decreasing across epochs, which indicates that the model is learning effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⭐ Predicted rating: 4 for User 0, Movie 2790 Age group  1\n"
     ]
    }
   ],
   "source": [
    "# Function to prepare input features for a single prediction\n",
    "def prepare_input(user_id, movie_id, gender_str, occupation_str, genres_list):\n",
    "    user = torch.tensor([user_id], dtype=torch.long)\n",
    "    movie = torch.tensor([movie_id], dtype=torch.long)\n",
    "    \n",
    "    gender_code = pd.Series([gender_str]).astype('category').cat.codes[0]\n",
    "    occupation_code = pd.Series([occupation_str]).astype('category').cat.codes[0]\n",
    "    \n",
    "    gender = torch.tensor([gender_code], dtype=torch.long)\n",
    "    occupation = torch.tensor([occupation_code], dtype=torch.long)\n",
    "    \n",
    "    genre_vec = torch.zeros(num_genres)\n",
    "    for genre in genres_list:\n",
    "        if genre in genre_to_idx:\n",
    "            genre_vec[genre_to_idx[genre]] = 1\n",
    "    genres = genre_vec.unsqueeze(0)\n",
    "    \n",
    "    return user, movie, gender, occupation, genres\n",
    "\n",
    "# Recreate the model architecture first\n",
    "test_model = FederatedRecommender(\n",
    "    num_users=num_users, \n",
    "    num_movies=num_movies, \n",
    "    num_genders=num_genders, \n",
    "    num_occupations=num_occupations, \n",
    "    num_genres=num_genres\n",
    ")\n",
    "\n",
    "# Sample input: Modify with actual known values from your dataset\n",
    "sample_row = df.iloc[15]\n",
    "\n",
    "sample_user_id = sample_row[\"UserID\"]   # 0-indexed\n",
    "sample_movie_id = sample_row[\"MovieID\"]  # 0-indexed\n",
    "sample_gender = sample_row[\"Gender\"]    # Gender column\n",
    "sample_occupation = sample_row[\"Occupation\"]  # Occupation column\n",
    "sample_genres = sample_row[\"Genres\"] \n",
    "\n",
    "# Extract the user's age (you would need to ensure there's a column for age or birthdate)\n",
    "user_age = sample_row[\"Age\"]  # Assuming there's an 'Age' column\n",
    "\n",
    "# Dynamically select the model based on age group\n",
    "# For example, if the user is between 18-25, load the model for age group 18\n",
    "age_group = 1 if (user_age // 10) * 10 ==0 else (user_age // 10) * 10 # This groups the ages (e.g., 20, 30, 40, etc.)\n",
    "\n",
    "model_filename = f\"client_models/client_model_{age_group}.pth\"\n",
    "test_model.load_state_dict(torch.load(model_filename))\n",
    "test_model.eval()\n",
    "\n",
    "# Prepare input\n",
    "user, movie, gender, occupation, genres = prepare_input(\n",
    "    sample_user_id, sample_movie_id, sample_gender, sample_occupation, sample_genres\n",
    ")\n",
    "\n",
    "# Predict\n",
    "with torch.no_grad():\n",
    "    predicted_rating = test_model(user, movie, gender, occupation, genres)\n",
    "\n",
    "    # Clamp between 1 and 5, then round to nearest int\n",
    "    predicted_rating = torch.clamp(predicted_rating, 1.0, 5.0)\n",
    "    predicted_rating = torch.round(predicted_rating)\n",
    "\n",
    "    print(f\"⭐ Predicted rating: {predicted_rating.item():.0f} for User {sample_user_id}, Movie {sample_movie_id} Age group  {age_group}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserID                        0\n",
      "MovieID                    2790\n",
      "Rating                        4\n",
      "Timestamp             978302188\n",
      "Gender                        0\n",
      "Age                           1\n",
      "Occupation                   10\n",
      "Zip-code                  48067\n",
      "Title          Airplane! (1980)\n",
      "Genres                 [Comedy]\n",
      "User                          0\n",
      "Movie                      2586\n",
      "Action                        0\n",
      "Adventure                     0\n",
      "Animation                     0\n",
      "Children's                    0\n",
      "Comedy                        1\n",
      "Crime                         0\n",
      "Documentary                   0\n",
      "Drama                         0\n",
      "Fantasy                       0\n",
      "Film-Noir                     0\n",
      "Horror                        0\n",
      "Musical                       0\n",
      "Mystery                       0\n",
      "Romance                       0\n",
      "Sci-Fi                        0\n",
      "Thriller                      0\n",
      "War                           0\n",
      "Western                       0\n",
      "Name: 15, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Federated model saved as federated_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Initialize the federated model (this is the final model that combines knowledge from all clients)\n",
    "federated_model = FederatedRecommender(\n",
    "    num_users=num_users, \n",
    "    num_movies=num_movies, \n",
    "    num_genders=num_genders, \n",
    "    num_occupations=num_occupations, \n",
    "    num_genres=num_genres\n",
    ")\n",
    "\n",
    "# Aggregation function: Average the weights from all local models\n",
    "def aggregate_local_models(local_models):\n",
    "    # Initialize an empty dictionary to hold the averaged weights\n",
    "    federated_weights = {}\n",
    "\n",
    "    # Initialize the federated model weights with zeroes (or the first model's weights)\n",
    "    for name, param in local_models[0].named_parameters():\n",
    "        federated_weights[name] = torch.zeros_like(param)\n",
    "\n",
    "    # Iterate through each local model and accumulate its weights\n",
    "    for model in local_models:\n",
    "        for name, param in model.named_parameters():\n",
    "            federated_weights[name] += param.data\n",
    "\n",
    "    # Average the accumulated weights\n",
    "    num_models = len(local_models)\n",
    "    for name, param in federated_weights.items():\n",
    "        federated_weights[name] /= num_models\n",
    "\n",
    "    return federated_weights\n",
    "\n",
    "# Aggregate the local models into the federated model\n",
    "aggregated_weights = aggregate_local_models(local_models)\n",
    "\n",
    "# Load the aggregated weights into the federated model\n",
    "federated_model.load_state_dict(aggregated_weights)\n",
    "\n",
    "# Save the federated model\n",
    "torch.save(federated_model.state_dict(), \"federated_model.pth\")\n",
    "print(\"💾 Federated model saved as federated_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the federated model for prediction\n",
    "federated_model.load_state_dict(torch.load(\"federated_model.pth\"))\n",
    "federated_model.eval()\n",
    "\n",
    "# Function to recommend movies using the federated model\n",
    "def recommend_movies_federated(user_id, gender, occupation, genres, num_recommendations=5):\n",
    "    all_movie_ids = range(num_movies)  # All possible movie IDs\n",
    "    movie_ratings = []\n",
    "\n",
    "    # Loop over all movie IDs to get predictions\n",
    "    for movie_id in all_movie_ids:\n",
    "        # Prepare the input for the model (ensure correct format for input)\n",
    "        user_tensor, movie_tensor, gender_tensor, occupation_tensor, genres_tensor = prepare_input(\n",
    "            user_id, movie_id, gender, occupation, genres\n",
    "        )\n",
    "        \n",
    "        # Predict the rating for the movie using the federated model\n",
    "        with torch.no_grad():\n",
    "            predicted_rating = federated_model(user_tensor, movie_tensor, gender_tensor, occupation_tensor, genres_tensor)\n",
    "            predicted_rating = torch.clamp(predicted_rating, 1.0, 5.0)  # Ensure it's between 1 and 5\n",
    "            movie_ratings.append((movie_id, predicted_rating.item()))\n",
    "\n",
    "    # Sort movies by predicted rating (highest to lowest)\n",
    "    movie_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Get the top N recommendations\n",
    "    top_recommendations = movie_ratings[:num_recommendations]\n",
    "    \n",
    "    # Create a list of movie names and predicted ratings to display\n",
    "    recommendations = []\n",
    "    for movie_id, rating in top_recommendations:\n",
    "        # Fetch the movie name from a movie_names dictionary\n",
    "        movie_name = movie_names.get(movie_id, f\"Unknown Movie {movie_id}\")  # If no name found, fallback to the movie ID\n",
    "        recommendations.append(f\"{movie_name}\")\n",
    "    \n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story (1995)\n",
      "Jumanji (1995)\n",
      "Grumpier Old Men (1995)\n",
      "Waiting to Exhale (1995)\n",
      "Father of the Bride Part II (1995)\n"
     ]
    }
   ],
   "source": [
    "# Function to get user input\n",
    "def get_user_input():\n",
    "    user_id = int(input(\"Enter User age: \"))\n",
    "    gender = input(\"Enter Gender (M/F): \")\n",
    "    occupation = input(\"Enter Occupation: \")\n",
    "    genres = input(\"Enter Preferred Genres (comma separated): \").split(\",\")\n",
    "    \n",
    "    return user_id, gender, occupation, genres\n",
    "\n",
    "# Get user input\n",
    "user_id, gender, occupation, genres = get_user_input()  # This should be a function to get user input\n",
    "recommendations = recommend_movies_federated(user_id, gender, occupation, genres, num_recommendations=5)\n",
    "\n",
    "# Print recommended movies\n",
    "for recommendation in recommendations:\n",
    "    print(recommendation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
